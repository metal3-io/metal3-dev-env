---
  - name: Define number of BMH's
    set_fact:
      NUMBER_OF_BMH: "{{ NUM_OF_MASTER_REPLICAS|int +  NUM_OF_WORKER_REPLICAS|int }}"

  - name: Remove ironic container from source cluster (Ephemeral Cluster is kind)
    docker_container:
      name: "{{ item }}"
      state: absent
    with_items:
       - ironic-api
       - ironic-conductor
       - ironic-inspector
       - dnsmasq
       - httpd
       - mariadb
       - ironic-endpoint-keepalived
       - ironic-log-watch
       - ironic-inspector-log-watch
    become: yes
    become_user: root
    when: EPHEMERAL_CLUSTER == "kind"

  - name: Remove Ironic from source cluster (Ephemeral Cluster is minikube)
    k8s:
      name: capm3-ironic
      kind: Deployment
      state: absent
      namespace: "{{ IRONIC_NAMESPACE }}"
    when: EPHEMERAL_CLUSTER == "minikube"

  - name: Label BMO CRDs.
    shell: 'kubectl label --overwrite crds baremetalhosts.metal3.io {{ item }}'
    with_items:
       - clusterctl.cluster.x-k8s.io=""
       - cluster.x-k8s.io/provider="metal3"
    when: CAPM3_VERSION == "v1alpha3"

  - name: Obtain target cluster kubeconfig
    k8s_info:
      kind: secrets
      name: "{{ CLUSTER_NAME }}-kubeconfig"
      namespace: "{{ NAMESPACE }}"
    register: metal3_kubconfig 

  - name: Filter, decode and save cluster kubeconfig 
    copy:
      content: "{{ metal3_kubconfig.resources[0].data.value | b64decode }}" 
      dest: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml" 

  - name: Create namespace
    k8s:
      name: "{{ NAMESPACE }}"
      kind: Namespace
      state: present
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"

  # Install BMO
  - name: Install Baremetal Operator
    shell: "{{ BMOPATH }}/tools/deploy.sh true false {{ IRONIC_TLS_SETUP }} {{ IRONIC_BASIC_AUTH }} true"
    environment:
      IRONIC_HOST: "{{ IRONIC_HOST }}"
      IRONIC_HOST_IP: "{{ IRONIC_HOST_IP }}"
      KUBECTL_ARGS: "{{ KUBECTL_ARGS }}"
    when: CAPM3_VERSION == "v1alpha3"

  # Configure Ironic configmap
  - name: Configure Ironic Configmap
    shell: |
      cp {{ BMOPATH }}/ironic-deployment/keepalived/ironic_bmo_configmap.env {{ BMOPATH }}/ironic-deployment/keepalived/ironic_bmo_configmap.env.orig
      cp {{ IRONIC_DATA_DIR }}/ironic_bmo_configmap.env  {{ BMOPATH }}/ironic-deployment/keepalived/ironic_bmo_configmap.env

  - name: Initialize Provider component in target cluster
    shell: "clusterctl init --kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml --core cluster-api:{{ CAPIRELEASE }} --bootstrap kubeadm:{{ CAPIRELEASE }} --control-plane kubeadm:{{ CAPIRELEASE }} --infrastructure metal3:{{ CAPM3RELEASE }} -v 5"

  # Check for cert-manager pods on the target cluster
  - name: Check if cert-manager  pods in running state
    shell: "kubectl get pods -n cert-manager -o json | jq -r '.items[].status.phase' | grep -cv Running"
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    retries: 20 
    delay: 20
    register: target_running_pods
    until: target_running_pods.stdout|int == 0
    failed_when: target_running_pods.stdout|int > 0

  # Install Ironic
  - name: Install Ironic
    shell: "{{ BMOPATH }}/tools/deploy.sh false true {{ IRONIC_TLS_SETUP }} {{ IRONIC_BASIC_AUTH }} true"
    environment:
      IRONIC_HOST: "{{ IRONIC_HOST }}"
      IRONIC_HOST_IP: "{{ IRONIC_HOST_IP }}"
      KUBECTL_ARGS: "{{ KUBECTL_ARGS }}"
 
  - name: Reinstate Ironic Configmap
    shell: "mv {{ BMOPATH }}/ironic-deployment/keepalived/ironic_bmo_configmap.env.orig {{ BMOPATH }}/ironic-deployment/keepalived/ironic_bmo_configmap.env"

  - name: Label BMO CRDs in target cluster.
    shell: 'kubectl --kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml label crds baremetalhosts.metal3.io {{ item }} --overwrite '
    with_items:
      - clusterctl.cluster.x-k8s.io=""
      - cluster.x-k8s.io/provider="metal3"
    when: CAPM3_VERSION == "v1alpha3"

  # Check for pods & nodes on the target cluster
  - name: Check if pods in running state
    shell: "kubectl get pods -A -o json | jq -r '.items[].status.phase' | grep -v Running"
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    retries: 150
    delay: 20
    register: target_running_pods
    failed_when: >
      (target_running_pods.stderr != "") or
      (target_running_pods.rc > 1) or
      (target_running_pods.stdout != "")
    until: target_running_pods.stdout == ""

  - name: Pivot objects to target cluster
    shell: "clusterctl move --to-kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml -n {{ NAMESPACE }} -v 10"

  - name: Check if machines become running.
    shell: |
        kubectl get machines -n {{ NAMESPACE }} -o json | jq -r '[ .items[]
        | select (.status.phase == "Running" or .status.phase == "running")
        | .metadata.name ] | length'
    register: provisioned_machines
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    retries: 50
    delay: 20
    until: provisioned_machines.stdout == NUMBER_OF_BMH

  - name: Check if metal3machines become provisioned.
    shell: |
        kubectl get m3m -n {{ NAMESPACE }} -o json | jq -r '[ .items[]
        | select (.status.ready == true)
        | .metadata.name ] | length'
    register: provisioned_m3m_machines
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    retries: 10
    delay: 20
    until: provisioned_m3m_machines.stdout == NUMBER_OF_BMH

  - name: Check if bmh is in provisioned state
    shell: |
        kubectl get bmh -n {{ NAMESPACE }} -o json | jq -r '[ .items[]
        | select (.status.provisioning.state == "provisioned")
        | .metadata.name ] | length'
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: provisioned_bmh
    retries: 10
    delay: 20
    until: provisioned_bmh.stdout ==  NUMBER_OF_BMH
