---
  - set_fact:
      NUMBER_OF_BMH_KCP: "{{ NUM_OF_MASTER_REPLICAS|int }}"
      NUMBER_OF_BMH_MD: "{{ NUM_OF_WORKER_REPLICAS|int }}"
      NUMBER_OF_ALL_BMH: "{{ NUM_OF_WORKER_REPLICAS|int + NUM_OF_MASTER_REPLICAS|int }}"

  - name: Untaint all nodes.
    shell: |
        kubectl taint nodes --all node-role.kubernetes.io/master-
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    ignore_errors: yes

  - name: Scale worker down to 0 to start testing KubeadmControlPlane node reuse test scenario.
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 0

  - name: Wait until worker is scaled down and "{{ NUMBER_OF_BMH_MD }}" BMH is Ready.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs
    retries: 200
    delay: 20
    until:
      - saved_bmhs is succeeded
      - saved_bmhs.resources | filter_provisioning("ready") | length == (NUMBER_OF_BMH_MD | int)

  - name: Get provisioned BMH names and UUIDs mapping before upgrade in KubeadmControlPlane node reuse test scenario.
    set_fact:
      bmh_before_upgrade_kcp: "{{ bmh_before_upgrade_kcp | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Update Metal3MachineTemplate nodeReuse field to 'True'.
    k8s:
      api_version: infrastructure.cluster.x-k8s.io/{{ CAPM3_VERSION }}
      kind: Metal3MachineTemplate
      name: "{{ CLUSTER_NAME }}-controlplane"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          nodeReuse: true

  - name: Upgrade KubeadmControlPlane k8s version from "{{ KUBERNETES_VERSION }}" to "{{ UPGRADED_K8S_VERSION }}" to test KCP scale-in feature.
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          version: "{{ UPGRADED_K8S_VERSION }}"
          rolloutStrategy:
            rollingUpdate:
              maxSurge: 0

  - pause:
      minutes: 1

  - name: Check if any of the machines is in Provisioning state.
    shell: |
        kubectl get machines -n "{{ NAMESPACE }}" -o json | jq -r '[ .items[] | select (.status.phase == "Provisioning") | .metadata.name ] | length'
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: provisioning_machine

  - name: Check if only single machine is in Deleting state and no other new machine is in Provisioning state while upgrade triggered to test the KCP scale-in feature.
    shell: |
        kubectl get machines -n "{{ NAMESPACE }}" -o json | jq -r '[ .items[] | select (.status.phase == "Deleting" or .status.phase == "deleting") | .metadata.name ] | length'
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: deleting_machines
    retries: 200
    delay: 2
    until: deleting_machines.stdout == NUMBER_OF_BMH_MD
    failed_when: >
       (provisioning_machine.stdout != "0") or
       (deleting_machines.stdout != NUMBER_OF_BMH_MD)

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" BMH is in deprovisioning state.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs
    retries: 150
    delay: 10
    until:
      - saved_bmhs is succeeded
      - saved_bmhs.resources | filter_provisioning("deprovisioning") | length == (NUMBER_OF_BMH_MD | int)

  - name: Wait until above deprovisioning BMHs are in Ready state again.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 2
    until:
      - bmhs is succeeded
      - (saved_bmhs.resources | filter_provisioning("deprovisioning") | map(attribute='metadata.name')) |
        intersect(bmhs.resources | filter_provisioning("ready") | map(attribute='metadata.name')) |
        length ==  (NUMBER_OF_BMH_MD | int)

  - name: Check if just deprovisioned and became ready BMH is re-used for next provisioning.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 150
    delay: 2
    until:
      - bmhs is succeeded
      - (saved_bmhs.resources | filter_provisioning("deprovisioning") | map(attribute='metadata.name')) |
        intersect(bmhs.resources | filter_provisioning("provisioning") | map(attribute='metadata.name')) |
        length == (NUMBER_OF_BMH_MD | int)

  - name: Wait until two machines become running and updated with new "{{ UPGRADED_K8S_VERSION }}" k8s version.
    shell: |
        kubectl get machines -n "{{ NAMESPACE }}" -o json | jq -r '.items[] | select (.status.phase == "Running") | select(.spec.version == "{{ UPGRADED_K8S_VERSION }}") | .status.phase' | grep -c "Running"
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: updated_machines_partly
    retries: 200
    delay: 20
    ignore_errors: yes
    until: updated_machines_partly.stdout|int > 1

  - pause:
      minutes: 5

  - name: Untaint all CP nodes after upgrade of two controlplane nodes.
    shell: |
        kubectl taint nodes --all node-role.kubernetes.io/master-
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    ignore_errors: yes

  - name: Wait until all "{{ NUMBER_OF_BMH_KCP }}" machines become running and updated with new "{{ UPGRADED_K8S_VERSION }}" k8s version.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    ignore_errors: yes
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | selectattr('spec.version', 'match', UPGRADED_K8S_VERSION) | length == (NUMBER_OF_BMH_KCP | int)

  - name: Get BMHs after upgrade in KubeadmControlPlane node reuse test scenario.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs

  - name: Get provisioned BMH names and UUIDs mapping after upgrade in KubeadmControlPlane node reuse test scenario.
    set_fact:
      bmh_after_upgrade_kcp: "{{ bmh_after_upgrade_kcp | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Check diff of before and after upgrade mappings to make sure same BMHs' were reused in KubeadmControlPlane node reuse test scenario.
    ansible.utils.fact_diff:
      before: "{{ bmh_before_upgrade_kcp }}"
      after: "{{ bmh_after_upgrade_kcp }}"
    register: diff_result
    failed_when: diff_result.changed

  - name: Put maxSurge field in KubeadmControlPlane back to default value(1).
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          rolloutStrategy:
            rollingUpdate:
              maxSurge: 1

  - name: Untaint all CP nodes.
    shell: |
        kubectl taint nodes --all node-role.kubernetes.io/master-
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    ignore_errors: yes

  - name: Scale controlplane down to 1.
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 1

  - pause:
      minutes: 5

  - name: Wait until controlplane is scaled down and "{{ NUMBER_OF_BMH_KCP }}" BMHs' are Ready.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 20
    until:
      - bmhs is succeeded
      - bmhs.resources | filter_provisioning("ready") | length == (NUMBER_OF_BMH_KCP | int)

  - name: Scale worker up to "{{ NUMBER_OF_BMH_MD }}" to start testing MachineDeployment node reuse test scenario.
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 1

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" more BMH is provisioned.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 20
    until:
      - bmhs is succeeded
      - bmhs.resources | filter_provisioning("provisioned") | length == 2

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" more machine becomes running.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | length == 2

  - name: Get BMHs before upgrade in MachineDeployment node reuse test scenario.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs

  - name: Get provisioned BMH names and UUIDs mapping before upgrade in MachineDeployment node reuse test scenario.
    set_fact:
      bmh_before_upgrade_md: "{{ bmh_before_upgrade_md | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Update fields maxSurge to 0 and maxUnavailable to 1 in MachineDeployment.
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          strategy:
            rollingUpdate:
              maxSurge: 0
              maxUnavailable: 1

  - name: Update Metal3MachineTemplate nodeReuse field to 'True'.
    k8s:
      api_version: infrastructure.cluster.x-k8s.io/{{ CAPM3_VERSION }}
      kind: Metal3MachineTemplate
      name: "{{ CLUSTER_NAME }}-workers"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          nodeReuse: True

  - name: List BMHs'.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs

  - name: Mark all ready BMHs' with unhealthy annotation.
    k8s:
      state: present
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      namespace: "{{ NAMESPACE }}"
      definition:
        apiVersion: metal3.io/v1alpha1
        kind: BareMetalHost
        metadata:
          name: "{{ item }}"
          annotations:
            capi.metal3.io/unhealthy: ""
    loop: "{{ bmhs.resources | filter_provisioning('ready') | map(attribute='metadata.name') }}"

  - name: Upgrade MachineDeployment k8s version from "{{ KUBERNETES_VERSION }}" to "{{ UPGRADED_K8S_VERSION }}".
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          template:
            spec:
              version: "{{ UPGRADED_K8S_VERSION }}"

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" BMH is in deprovisioning state.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs
    retries: 150
    delay: 10
    until: saved_bmhs.resources | filter_provisioning("deprovisioning") | length == (NUMBER_OF_BMH_MD | int)

  - name: Wait until above deprovisioning BMH is in Ready state again.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 2
    until:
      - bmhs is succeeded
      - (saved_bmhs.resources | filter_provisioning("deprovisioning") | map(attribute='metadata.name')) |
        intersect(bmhs.resources | filter_provisioning("ready") | map(attribute='metadata.name')) |
        length == (NUMBER_OF_BMH_MD | int)

  - name: Unmark all ready BMHs' with unhealthy annotation.
    k8s:
      state: present
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      namespace: "{{ NAMESPACE }}"
      definition:
        apiVersion: metal3.io/v1alpha1
        kind: BareMetalHost
        metadata:
          name: "{{ item }}"
          annotations:
            capi.metal3.io/unhealthy: null
    loop: "{{ saved_bmhs.resources | map(attribute='metadata.name') }}"

  - name: Check if just deprovisioned and became ready BMH is re-used for next provisioning.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 2
    until:
      - bmhs is succeeded
      - (saved_bmhs.resources | filter_provisioning("deprovisioning") | map(attribute='metadata.name')) |
        intersect(bmhs.resources | filter_provisioning("provisioning") | map(attribute='metadata.name')) |
        length == (NUMBER_OF_BMH_MD | int)

  - name: Wait until worker machine becomes running and updated with new "{{ UPGRADED_K8S_VERSION }}" k8s version.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | selectattr('spec.version', 'match', UPGRADED_K8S_VERSION) | length == 2

  - name: Get BMHs after upgrade in MachineDeployment node reuse test scenario.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs

  - name: Get provisioned BMH names and UUIDs mapping after upgrade in MachineDeployment node reuse test scenario.
    set_fact:
      bmh_after_upgrade_md: "{{ bmh_after_upgrade_md | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Check diff of before and after upgrade mapping to make sure same BMH reused in MachineDeployment node reuse test scenario.
    ansible.utils.fact_diff:
      before: "{{ bmh_before_upgrade_md }}"
      after: "{{ bmh_after_upgrade_md }}"
    register: diff_result
    failed_when: diff_result.changed

  - name: Scale controlplane up back to 3.
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 3

  - name: Wait until all "{{ NUMBER_OF_ALL_BMH }}" BMHs' are provisioned.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 20
    until:
      - bmhs is succeeded
      - bmhs.resources | filter_provisioning("provisioned") | length == (NUMBER_OF_ALL_BMH | int)

  - name: Wait until all "{{ NUMBER_OF_ALL_BMH }}" machines become running.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | length == (NUMBER_OF_ALL_BMH | int)
