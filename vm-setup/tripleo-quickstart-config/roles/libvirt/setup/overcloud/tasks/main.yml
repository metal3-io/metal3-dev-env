- name: Include vars for libvirt-libvirt-nodepool
  include_vars:
    file: libvirt_nodepool_vars.yml
  when: libvirt_nodepool|default(false)

- when: overcloud_nodes
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:

    # ensure python-netaddr is installed for next task
    - name: ensure python-netaddr
      become: true
      package:
        name: python-netaddr
        state: present

    # Create libvirt volumes for the overcloud hosts.
    - name: Check if overcloud volumes exist
      command: >
        virsh vol-info --pool '{{ libvirt_volume_pool }}' '{{ item.name }}.qcow2'
      register: overcloud_vol_check
      ignore_errors: true
      with_items: "{{ overcloud_nodes }}"

    - name: Create overcloud vm storage
      command: >
        virsh vol-create-as '{{ libvirt_volume_pool }}'
        '{{ item.item.name }}'.qcow2 '{{ flavors[item.item.flavor].disk }}'G
        --format qcow2
      when:
        - item is failed
        - not libvirt_nodepool_vms|default("false")|bool
      with_items: "{{ overcloud_vol_check.results }}"

    # Define (but do not start) the overcloud nodes.  These will be
    # booted later by ironic during the provisioning process.
    - name: Define overcloud vms
      virt:
        name: "{{ item.name }}"
        command: define
        xml: "{{ lookup('template', 'baremetalvm.xml.j2') }}"
        uri: "{{ libvirt_uri }}"
      with_items: "{{ overcloud_nodes }}"
      when: not libvirt_nodepool_vms|default("false")|bool

    - name: Define overcloud vms
      virt:
        name: "{{ item.name }}"
        command: define
        xml: "{{ lookup('template', 'libvirtnodepoolvm.xml.j2') }}"
        uri: "{{ libvirt_uri }}"
      with_items: "{{ overcloud_nodes }}"
      when: libvirt_nodepool_vms|default("false")|bool

    - include_tasks: libvirt_nodepool.yml
      when: libvirt_nodepool_vms|default("false")|bool

    # Create additional blockdevices for each objectstorage flavor node
    # These are sparse files, not using space if unused
    - name: Create additional blockdevice for objectstorage nodes
      command: >
        dd if=/dev/zero of={{ libvirt_volume_path }}/{{ item[0].name }}_{{ item[1] }}.img bs=1 count=0 seek={{ extradisks_size }}
      when: flavors[item[0].flavor].extradisks|default(false)
      with_nested:
        - "{{ overcloud_nodes }}"
        - "{{ extradisks_list }}"

    - name: Check if additional blockdevices are attached
      command: >
        virsh domblkinfo {{ item[0].name }} {{ libvirt_volume_path }}/{{ item[0].name }}_{{ item[1] }}.img
      when: flavors[item[0].flavor].extradisks|default(false)
      changed_when: false
      ignore_errors: true
      register: overcloud_extradisks_check
      with_nested:
        - "{{ overcloud_nodes }}"
        - "{{ extradisks_list }}"

    - name: Attach additional blockdevices to overcloud objectstorage VMs
      command: >
        virsh attach-disk --config {{ item.item[0].name }} {{ libvirt_volume_path }}/{{ item.item[0].name }}_{{ item.item[1] }}.img {{ item.item[1] }}
      when: item is failed
      with_items: "{{ overcloud_extradisks_check.results }}"

# Generate the ironic node inventory files.  Note that this
# task *must* occur after the above overcloud tasks, because if
# `overcloud_nodes` is defined the template depends on the
# `node_mac_map` variable.
- name: Write ironic node json files
  template:
    src: ../templates/ironic_nodes.json.j2
    dest: "{{ working_dir }}/ironic_nodes.json"
