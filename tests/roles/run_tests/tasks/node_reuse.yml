---
  - set_fact:
      NUMBER_OF_BMH_KCP: "{{ NUM_OF_CONTROLPLANE_REPLICAS|int }}"
      NUMBER_OF_BMH_MD: "{{ NUM_OF_WORKER_REPLICAS|int }}"

  - name: Untaint all nodes.
    shell: |
        kubectl taint nodes --all node-role.kubernetes.io/control-plane-
        kubectl taint nodes --all node-role.kubernetes.io/master-
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    ignore_errors: yes

  - name: Scale worker down to 0 to start testing KubeadmControlPlane node reuse test scenario.
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 0

  - name: Wait until worker is scaled down and "{{ NUMBER_OF_BMH_MD }}" BMH is available.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs
    retries: 2000
    delay: 200
    until:
      - saved_bmhs is succeeded
      - saved_bmhs.resources | filter_provisioning("available,ready") | length == (NUMBER_OF_BMH_MD | int)
  - pause:
      minutes: 600
  - name: Get provisioned BMH names and UUIDs mapping before upgrade in KubeadmControlPlane node reuse test scenario.
    set_fact:
      bmh_before_upgrade_kcp: "{{ bmh_before_upgrade_kcp | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Download upgraded boot-disk image for deployment
    include_tasks: download_image.yml
    vars:
      IMAGE_NAME: "{{ UPGRADED_IMAGE_NAME }}"
      RAW_IMAGE_NAME: "{{ UPGRADED_RAW_IMAGE_NAME }}"
      IMAGE_LOCATION: "https://artifactory.nordix.org/artifactory/metal3/images/k8s_{{UPGRADED_K8S_VERSION}}"
      IMAGE_URL: "http://172.22.0.1/images/{{ RAW_IMAGE_NAME }}"
      IMAGE_CHECKSUM: "http://172.22.0.1/images/{{ RAW_IMAGE_NAME }}.{{ IMAGE_CHECKSUM_TYPE }}sum"

  - name: Update KCP Metal3MachineTemplate with upgraded image and nodeReuse field set to 'True'.
    k8s:
      api_version: infrastructure.cluster.x-k8s.io/{{ CAPM3_VERSION }}
      kind: Metal3MachineTemplate
      name: "{{ CLUSTER_NAME }}-controlplane"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          nodeReuse: true
          template:
            spec:
              image:
                checksum: "http://172.22.0.1/images/{{ UPGRADED_RAW_IMAGE_NAME }}.{{ IMAGE_CHECKSUM_TYPE }}sum"
                checksumType: "{{IMAGE_CHECKSUM_TYPE}}"
                format: "{{IMAGE_FORMAT}}"
                url: "http://172.22.0.1/images/{{ UPGRADED_RAW_IMAGE_NAME }}"

  - name: Change KCP to upgrade k8s version and binaries from "{{ KUBERNETES_VERSION }}" to "{{ UPGRADED_K8S_VERSION }}".
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          version: "{{ UPGRADED_K8S_VERSION }}"
          rolloutStrategy:
            rollingUpdate:
              maxSurge: 0

  - pause:
      minutes: 1

  - name: Check if any of the machines is in Provisioning state.
    shell: |
        kubectl get machines -n "{{ NAMESPACE }}" -o json | jq -r '[ .items[] | select (.status.phase == "Provisioning") | .metadata.name ] | length'
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: provisioning_machine

  - name: Check if only single machine is in Deleting state and no other new machine is in Provisioning state while upgrade triggered to test the KCP scale-in feature.
    shell: |
        kubectl get machines -n "{{ NAMESPACE }}" -o json | jq -r '[ .items[] | select (.status.phase == "Deleting" or .status.phase == "deleting") | .metadata.name ] | length'
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: deleting_machines
    retries: 200
    delay: 2
    until: deleting_machines.stdout == NUMBER_OF_BMH_MD
    failed_when: >
       (provisioning_machine.stdout != "0") or
       (deleting_machines.stdout != NUMBER_OF_BMH_MD)

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" BMH is in deprovisioning state.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs
    retries: 150
    delay: 10
    until:
      - saved_bmhs is succeeded
      - saved_bmhs.resources | filter_provisioning("deprovisioning") | length == (NUMBER_OF_BMH_MD | int)

  - name: Wait until the previously deprovisioned BMH becomes available.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 2
    until:
      - bmhs is succeeded
      - saved_bmhs.resources | filter_provisioning("deprovisioning") | first | json_query('metadata.name') in (
        bmhs.resources | filter_provisioning("available,ready") | map(attribute='metadata.name')
        )

  - name: Check if just deprovisioned BMH is re-used for the next provisioning.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 150
    delay: 2
    until:
      - bmhs is succeeded
      - bmhs.resources | filter_provisioning("provisioning") | length == 1
      - saved_bmhs.resources | filter_provisioning("deprovisioning") | first | json_query('metadata.name') ==
        bmhs.resources | filter_provisioning("provisioning") | first | json_query('metadata.name')

  - name: Wait until two machines become running and updated with new "{{ UPGRADED_K8S_VERSION }}" k8s version.
    shell: |
        kubectl get machines -n "{{ NAMESPACE }}" -o json | jq -r '.items[] | select (.status.phase == "Running") | select(.spec.version == "{{ UPGRADED_K8S_VERSION }}") | .status.phase' | grep -c "Running"
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: updated_machines_partly
    retries: 200
    delay: 20
    ignore_errors: yes
    until: updated_machines_partly.stdout|int > 1

  - pause:
      minutes: 5

  - name: Untaint all CP nodes after upgrade of two controlplane nodes.
    shell: |
        kubectl taint nodes --all node-role.kubernetes.io/control-plane-
        kubectl taint nodes --all node-role.kubernetes.io/master-
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    ignore_errors: yes

  - name: Wait until all "{{ NUMBER_OF_BMH_KCP }}" machines become running and updated with new "{{ UPGRADED_K8S_VERSION }}" k8s version.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    ignore_errors: yes
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | selectattr('spec.version', 'match', UPGRADED_K8S_VERSION) | length == (NUMBER_OF_BMH_KCP | int)

  - name: Get BMHs after upgrade in KubeadmControlPlane node reuse test scenario.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs

  - name: Get provisioned BMH names and UUIDs mapping after upgrade in KubeadmControlPlane node reuse test scenario.
    set_fact:
      bmh_after_upgrade_kcp: "{{ bmh_after_upgrade_kcp | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Check diff of before and after upgrade mappings to make sure same BMHs' were reused in KubeadmControlPlane node reuse test scenario.
    ansible.utils.fact_diff:
      before: "{{ bmh_before_upgrade_kcp }}"
      after: "{{ bmh_after_upgrade_kcp }}"
    register: diff_result
    failed_when: diff_result.changed

  - name: Put maxSurge field in KubeadmControlPlane back to default value(1).
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          rolloutStrategy:
            rollingUpdate:
              maxSurge: 1

  - name: Untaint all CP nodes.
    shell: |
        kubectl taint nodes --all node-role.kubernetes.io/control-plane-
        kubectl taint nodes --all node-role.kubernetes.io/master-
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    ignore_errors: yes

  - name: Scale controlplane down to 1.
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 1

  - name: Wait until controlplane is scaled down and "{{ NUMBER_OF_BMH_KCP }}" BMHs' are available.
    shell: kubectl get bmh -n "{{ NAMESPACE }}" | egrep -c '\b(available)|(ready)\b'
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: num_available_bmhs
    retries: 200
    delay: 30
    until: num_available_bmhs.stdout == "3"

  - name: Scale worker up to "{{ NUMBER_OF_BMH_MD }}" to start testing MachineDeployment node reuse test scenario.
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 1

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" more BMH is provisioned.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 20
    until:
      - bmhs is succeeded
      - bmhs.resources | filter_provisioning("provisioned") | length == 2

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" more machine becomes running.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | length == 2

  - name: Get BMHs before upgrade in MachineDeployment node reuse test scenario.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs

  - name: Get provisioned BMH names and UUIDs mapping before upgrade in MachineDeployment node reuse test scenario.
    set_fact:
      bmh_before_upgrade_md: "{{ bmh_before_upgrade_md | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Update fields maxSurge to 0 and maxUnavailable to 1 in MachineDeployment.
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          strategy:
            rollingUpdate:
              maxSurge: 0
              maxUnavailable: 1

  - name: List BMHs'.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs

  - name: Remove nodeReuse label from all available BMHs.
    k8s:
      state: present
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      namespace: "{{ NAMESPACE }}"
      definition:
        apiVersion: metal3.io/v1alpha1
        kind: BareMetalHost
        metadata:
          name: "{{ item }}"
          labels:
            infrastructure.cluster.x-k8s.io/node-reuse: null
    loop: "{{ bmhs.resources | filter_provisioning('available,ready') | map(attribute='metadata.name') }}"

  - name: Update MD Metal3MachineTemplate with upgraded image and nodeReuse field set to 'True'.
    k8s:
      api_version: infrastructure.cluster.x-k8s.io/{{ CAPM3_VERSION }}
      kind: Metal3MachineTemplate
      name: "{{ CLUSTER_NAME }}-workers"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          nodeReuse: true
          template:
            spec:
              image:
                checksum: "http://172.22.0.1/images/{{ UPGRADED_RAW_IMAGE_NAME }}.{{ IMAGE_CHECKSUM_TYPE }}sum"
                checksumType: "{{IMAGE_CHECKSUM_TYPE}}"
                format: "{{IMAGE_FORMAT}}"
                url: "http://172.22.0.1/images/{{ UPGRADED_RAW_IMAGE_NAME }}"

  - name: Change MD to upgrade k8s version and binaries from "{{ KUBERNETES_VERSION }}" to "{{ UPGRADED_K8S_VERSION }}".
    k8s:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: MachineDeployment
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          template:
            spec:
              version: "{{ UPGRADED_K8S_VERSION }}"

  - name: Wait until "{{ NUMBER_OF_BMH_MD }}" BMH is in deprovisioning state.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs
    retries: 150
    delay: 10
    until: saved_bmhs.resources | filter_provisioning("deprovisioning") | length == (NUMBER_OF_BMH_MD | int)

  - name: Wait until the previously deprovisioned BMH becomes available.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 2
    until:
      - bmhs is succeeded
      - saved_bmhs.resources | filter_provisioning("deprovisioning") | first | json_query('metadata.name') in (
        bmhs.resources | filter_provisioning("available,ready") | map(attribute='metadata.name')
        )

  - name: Check if just deprovisioned BMH is re-used for the next provisioning.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: bmhs
    retries: 200
    delay: 2
    until:
      - bmhs is succeeded
      - bmhs.resources | filter_provisioning("provisioning") | length == 1
      - saved_bmhs.resources | filter_provisioning("deprovisioning") | first | json_query('metadata.name') ==
        bmhs.resources | filter_provisioning("provisioning") | first | json_query('metadata.name')

  - name: Wait until worker machine becomes running and updated with new "{{ UPGRADED_K8S_VERSION }}" k8s version.
    k8s_info:
      api_version: cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: machines
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: machines
    retries: 200
    delay: 20
    until:
      - machines is succeeded
      - machines.resources | filter_phase("running") | selectattr('spec.version', 'match', UPGRADED_K8S_VERSION) | length == 2

  - name: Get BMHs after upgrade in MachineDeployment node reuse test scenario.
    k8s_info:
      api_version: metal3.io/v1alpha1
      kind: BareMetalHost
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: saved_bmhs

  - name: Get provisioned BMH names and UUIDs mapping after upgrade in MachineDeployment node reuse test scenario.
    set_fact:
      bmh_after_upgrade_md: "{{ bmh_after_upgrade_md | default([]) + ['metal3/' + item.metadata.name + '=metal3://' + item.metadata.uid] }}"
    with_items: "{{ saved_bmhs.resources | filter_provisioning('provisioned') }}"

  - name: Check diff of before and after upgrade mapping to make sure same BMH reused in MachineDeployment node reuse test scenario.
    ansible.utils.fact_diff:
      before: "{{ bmh_before_upgrade_md }}"
      after: "{{ bmh_after_upgrade_md }}"
    register: diff_result
    failed_when: diff_result.changed

  - name: Scale controlplane up back to 3.
    k8s:
      api_version: controlplane.cluster.x-k8s.io/{{ CAPI_VERSION }}
      kind: KubeadmControlPlane
      name: "{{ CLUSTER_NAME }}"
      namespace: "{{ NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition:
        spec:
          replicas: 3

  - name: Verify that all machines are provisioned and running.
    include_tasks: verify_resources_states.yml
    vars:
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
