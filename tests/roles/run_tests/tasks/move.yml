---
  - name: Define number of BMH's
    set_fact:
      NUMBER_OF_BMH: "{{ CONTROL_PLANE_MACHINE_COUNT|int +  WORKER_MACHINE_COUNT|int }}"
      general_containers:
          - httpd-infra
          - registry
          - sushy-tools
          - vbmc
      ironic_containers:
          - ironic
          - ironic-endpoint-keepalived
          - ironic-log-watch
          - dnsmasq

  - name: Fetch container logs (kind cluster)
    block:

      - name: Create directories for storing container logs (kind cluster)
        file:
          path: "/tmp/{{ CONTAINER_RUNTIME }}/{{ item }}"
          state: directory
        with_items:
          - "{{ ironic_containers }}"
          - "{{ general_containers }}"

      - name: Fetch container logs before pivoting (kind cluster)
        shell: "sudo {{ CONTAINER_RUNTIME }} logs {{ item }} > /tmp/{{ CONTAINER_RUNTIME }}/{{ item }}/stdout.log 2> /tmp/{{ CONTAINER_RUNTIME }}/{{ item }}/stderr.log"
        with_items:
          - "{{ ironic_containers }}"
          - "{{ general_containers }}"

      - name: Remove ironic container from source cluster (kind cluster)
        docker_container:
          name: "{{ item }}"
          state: absent
        with_items: "{{ ironic_containers }}"

    when: EPHEMERAL_CLUSTER == "kind"
    become: true
    become_user: root

  - name: Fetch container logs (minikube cluster)
    block:

      - name: Create directories for storing container logs (minikube cluster)
        file:
          path: "/tmp/{{ CONTAINER_RUNTIME }}/{{ item }}"
          state: directory
        with_items: "{{ general_containers }}"

      - name: Fetch container logs before pivoting (minikube cluster)
        shell: "sudo {{ CONTAINER_RUNTIME }} logs {{ item }} > /tmp/{{ CONTAINER_RUNTIME }}/{{ item }}/stdout.log 2> /tmp/{{ CONTAINER_RUNTIME }}/{{ item }}/stderr.log"
        with_items: "{{ general_containers }}"

    become: true
    become_user: root
    when: EPHEMERAL_CLUSTER == "minikube"

  - name: Remove Ironic CR from source cluster (minikube cluster)
    kubernetes.core.k8s:
      name: ironic
      kind: Ironic
      api_version: ironic.metal3.io/v1alpha1
      state: absent
      namespace: "{{ IRONIC_NAMESPACE }}"
    when: EPHEMERAL_CLUSTER == "minikube"

  - name: Remove IRSO from source cluster (minikube cluster)
    shell: "make -C {{ IRSOPATH }} uninstall undeploy"
    ignore_errors: true
    when: EPHEMERAL_CLUSTER == "minikube"

  - name: Label baremetalhost CRD to pivot.
    shell: "kubectl label --overwrite crds baremetalhosts.metal3.io {{ item }}"
    with_items:
       - clusterctl.cluster.x-k8s.io=""
       - clusterctl.cluster.x-k8s.io/move=""
       - clusterctl.cluster.x-k8s.io/move-hierarchy=""

  - name: Label hardwareData CRD to pivot.
    shell: "kubectl label --overwrite crds hardwaredata.metal3.io {{ item }}"
    with_items:
       - clusterctl.cluster.x-k8s.io=""
       - clusterctl.cluster.x-k8s.io/move=""

  - name: Obtain target cluster kubeconfig
    kubernetes.core.k8s_info:
      kind: secrets
      name: "{{ CLUSTER_NAME }}-kubeconfig"
      namespace: "{{ NAMESPACE }}"
    register: metal3_kubeconfig

  - name: Decode and save cluster kubeconfig
    copy:
      content: "{{ metal3_kubeconfig.resources[0].data.value | b64decode }}"
      dest: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"

  - name: Create namespace
    kubernetes.core.k8s:
      name: "{{ NAMESPACE }}"
      kind: Namespace
      state: present
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"

  - name: Initialize Provider component in target cluster
    vars:
      ipam_release: "{{ lookup('env', 'IPAMRELEASE') }}"
    shell: " clusterctl init --kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml --core cluster-api:{{ CAPIRELEASE }} --bootstrap kubeadm:{{ CAPIRELEASE }} --control-plane kubeadm:{{ CAPIRELEASE }} --infrastructure metal3:{{ CAPM3RELEASE }} -v 5"
    when: ipam_release == 'v1.7.99' or ipam_release == 'v1.8.99' or ipam_release == 'v1.9.99'

  # Making IPAM a provider for capi is merged in 1.10
  # TODO: Remove this check when 1.9 is no longer tested. Remember to edit above
  # block as well.
  - name: Initialize Provider component in target cluster
    vars:
      ipam_release: "{{ lookup('env', 'IPAMRELEASE') }}"
    shell: "clusterctl init --kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml --core cluster-api:{{ CAPIRELEASE }} --bootstrap kubeadm:{{ CAPIRELEASE }} --control-plane kubeadm:{{ CAPIRELEASE }} --infrastructure metal3:{{ CAPM3RELEASE }} -v 5 --ipam metal3:{{ IPAMRELEASE }}"
    when: ipam_release != 'v1.7.99' and ipam_release != 'v1.8.99' and ipam_release != 'v1.9.99'

  # Check for cert-manager pods on the target cluster
  - name: Check if cert-manager  pods in running state
    kubernetes.core.k8s_info:
      kind: pods
      namespace: cert-manager
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      field_selectors:
        - status.phase!=Running
    register: target_running_pods
    retries: 20
    delay: 20
    until: (target_running_pods is succeeded) and
           (target_running_pods.resources | length == 0)

  # Install BMO
  - name: Install Baremetal Operator
    shell: "{{ BMOPATH }}/tools/deploy.sh -b {{ BMO_IRONIC_ARGS }}"
    environment:
      IRONIC_HOST: "{{ IRONIC_HOST }}"
      IRONIC_HOST_IP: "{{ IRONIC_HOST_IP }}"
      KUBECTL_ARGS: "{{ KUBECTL_ARGS }}"
    args:
      chdir: "{{ BMOPATH }}"

  # Install IRSO and Ironic via IRSO
  - name: Set IPA_BASEURI in IRSO manager config
    lineinfile:
      path: "{{ IRSOPATH }}/config/manager/manager.env"
      line: 'IPA_BASEURI=https://artifactory.nordix.org/artifactory/openstack-remote-cache/ironic-python-agent/dib'
      create: yes

  - name: Install and deploy IRSO
    shell: "make install deploy IMG={{ IRSO_IMAGE }}"
    args:
      chdir: "{{ IRSOPATH }}"
    environment:
      KUBECONFIG: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"

  - name: Wait for IRSO controller manager to be available
    kubernetes.core.k8s_info:
      kind: Deployment
      name: ironic-standalone-operator-controller-manager
      namespace: ironic-standalone-operator-system
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      wait: true
      wait_condition:
        type: Available
        status: "True"
      wait_timeout: 60

  - name: Set Ironic spec
    set_fact:
      ironic_spec:
        apiVersion: ironic.metal3.io/v1alpha1
        kind: Ironic
        metadata:
          name: ironic
          namespace: "{{ IRONIC_NAMESPACE }}"
        spec:
          images:
            deployRamdiskBranch: "{{ IPA_BRANCH }}"
            deployRamdiskDownloader: "{{ IPA_DOWNLOADER_IMAGE }}"
            ironic: "{{ IRONIC_IMAGE }}"
            keepalived: "{{ IRONIC_KEEPALIVED_IMAGE }}"
          version: "{{ IRSO_IRONIC_VERSION }}"
          networking:
            dhcp:
              rangeBegin: "{{ CLUSTER_DHCP_RANGE_START }}"
              rangeEnd: "{{ CLUSTER_DHCP_RANGE_END }}"
              networkCIDR: "{{ BARE_METAL_PROVISIONER_NETWORK }}"
            interface: "{{ BARE_METAL_PROVISIONER_INTERFACE }}"
            ipAddress: "{{ CLUSTER_BARE_METAL_PROVISIONER_IP }}"
            ipAddressManager: keepalived
          deployRamdisk:
            sshKey: "{{ SSH_PUB_KEY_CONTENT }}"

  - name: Add extraKernelParams for libvirt platform
    set_fact:
      ironic_spec: "{{ ironic_spec | combine({'spec': {'deployRamdisk': {'extraKernelParams': 'console=ttyS0'}}}, recursive=True) }}"
    when: NODES_PLATFORM == 'libvirt'

  - name: Deploy Ironic using IRSO (retry if webhook not ready)
    kubernetes.core.k8s:
      state: present
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      definition: "{{ ironic_spec }}"
    register: ironic_create
    retries: 10
    delay: 3
    until: ironic_create is succeeded

  - name: Wait for Ironic to be ready
    kubernetes.core.k8s_info:
      kind: Ironic
      name: ironic
      namespace: "{{ IRONIC_NAMESPACE }}"
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      wait: true
      wait_condition:
        type: Ready
        status: "True"
      wait_timeout: "{{ (IRONIC_ROLLOUT_WAIT | default(10) | int * 60) }}"

  - name: Label baremetalhost CRD in target cluster to pivot back.
    shell: "kubectl --kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml label crds baremetalhosts.metal3.io {{ item }} --overwrite "
    with_items:
      - clusterctl.cluster.x-k8s.io=""
      - clusterctl.cluster.x-k8s.io/move=""
      - clusterctl.cluster.x-k8s.io/move-hierarchy=""

  - name: Label hardwareData CRD in target cluster to pivot back.
    shell: "kubectl --kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml label crds hardwaredata.metal3.io {{ item }} --overwrite "
    with_items:
       - clusterctl.cluster.x-k8s.io=""
       - clusterctl.cluster.x-k8s.io/move=""

  # Check for pods & nodes on the target cluster
  - name: Check if pods in running state
    kubernetes.core.k8s_info:
      kind: pods
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
      field_selectors:
        - status.phase!=Running
    register: target_running_pods
    retries: 150
    delay: 20
    until: (target_running_pods is succeeded) and
           (target_running_pods.resources | length == 0)

  - name: Check if all deployments replicas are available
    kubernetes.core.k8s_info:
      kind: Deployment
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"
    register: deployments
    retries: 150
    delay: 20
    until: (deployments is succeeded) and
           (deployments.resources | filter_unavailable_replicas | length == 0 )

  - name: Pivot objects to target cluster
    shell: "clusterctl move --to-kubeconfig /tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml -n {{ NAMESPACE }} -v 10"

  - name: Remove BMO deployment from source cluster
    kubernetes.core.k8s:
      name: "{{ NAMEPREFIX }}-controller-manager"
      kind: Deployment
      state: absent
      namespace: "{{ IRONIC_NAMESPACE }}"

  - name: Verify that all machines are provisioned and running.
    include_tasks: verify_resources_states.yml
    vars:
      kubeconfig: "/tmp/kubeconfig-{{ CLUSTER_NAME }}.yaml"

  # Normally as non authenticated user we should
  # fail here(get 401) to reach Ironic.
  - name: Expect 401 from /v1/nodes ednpoint
    uri:
      url: "{{ IRONIC_URL }}nodes"
      return_content: no
      validate_certs: no
      method: GET
      status_code: [401]
